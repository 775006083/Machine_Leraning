{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TP1__Linear_Regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lpO8Roo99Fys"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import random  # utilisé pour le choix aléatoire d'une ligne de X pour le gradient_stochastique"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"w1c_FffGNWSR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cd /content/drive/MyDrive/"],"metadata":{"id":"JB6GWZduOc6i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Veuillez mettre en œuvre les tâches suivantes :"],"metadata":{"id":"sWsQ04OK-63J"}},{"cell_type":"markdown","source":["1. Un fichier csv contenant l'ensemble de données sera partagé, téléchargez-le et téléchargez-le."],"metadata":{"id":"yhJ1nV9Y9UIU"}},{"cell_type":"markdown","source":["2. Lisez le fichier csv en utilisant Pandas."],"metadata":{"id":"YfIQQGRQ-5W4"}},{"cell_type":"code","source":["data = pd.read_csv(\"/content/drive/MyDrive/apprentissage_supervise/classwork-data.csv\") # write the path of the data file here\n"],"metadata":{"id":"c2Q8nMwXCWlS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head()"],"metadata":{"id":"rgyuWm484Qiw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Créez une variable X en numpy array pour les colonnes d'entrée (col1, col2, col3, col4)."],"metadata":{"id":"CzwBx2kmDTEO"}},{"cell_type":"markdown","source":["Transformer le tableau pandas en Numpy"],"metadata":{"id":"G-nTRfWNW-FX"}},{"cell_type":"code","source":["X =  data.iloc[:,1:5].values \n","X"],"metadata":{"id":"oH1Vfx--VMQu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.shape"],"metadata":{"id":"PZTdH3JL2Wrn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. Créez une variable Y pour la colonne de sortie (cible)."],"metadata":{"id":"tnWjO0oQErwW"}},{"cell_type":"code","source":["Y  =  data.iloc[:,-1].values"],"metadata":{"id":"oVxovq0QE8ft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y"],"metadata":{"id":"m-2W-Z9S2wn3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y.shape"],"metadata":{"id":"giXOntNb22yN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y = Y.reshape(Y.shape[0],1)"],"metadata":{"id":"MKo81I6vmunN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y.shape"],"metadata":{"id":"krGOf4pDm3nP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y"],"metadata":{"id":"4gIWS3b-tA-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#################################################################################################################"],"metadata":{"id":"gqQlEiEG3Kev"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5. Divisez l'ensemble de données en deux ensembles, l'ensemble de formation et l'ensemble de test.\n","* Vérifiez en ligne [ici] (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) comment utiliser la fonction **train_test_split** de la bibliothèque sklearn."],"metadata":{"id":"XB8hdptqFN2F"}},{"cell_type":"code","source":["# You need to find:   X_train, X_test, Y_train, Y_test\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n","                                test_size=0.2, random_state=42)"],"metadata":{"id":"o3-TGQDtFSHj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"id":"9LJCfGbo5XyT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test.shape"],"metadata":{"id":"GIc-5XRH5cI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_train.shape"],"metadata":{"id":"lqhiIktSnGjK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#################################################################################################################"],"metadata":{"id":"N-0ZbhLJ3NV-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6. Utilisez l'erreur quadratique moyenne pour rendre compte de la performance du modèle de régression linéaire."],"metadata":{"id":"ReOn2cPsMnZw"}},{"cell_type":"markdown","source":["$$\n","MSE = \\frac{\\sum{(target - prediction)^2}}{n}\n","$$"],"metadata":{"id":"VbuJOlY0wFWu"}},{"cell_type":"code","source":["# define the MSE fun\n","def MSE(y_true, y_pred):\n","  # calculate the MSE and return it\n","  n = len(y_true)\n","  mse = (np.sum(np.square(y_true - y_pred)))*(1/n)\n","  return mse"],"metadata":{"id":"unYqUDO9M1fh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#################################################################################################################"],"metadata":{"id":"gKZCEGVv3Omi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7. Implémenter la fonction MLE, qui calcule l'estimateur du maximum de vraisemblance pour les données données."],"metadata":{"id":"J0EQrxBINsfO"}},{"cell_type":"markdown","source":["Calculez le paramètre du modèle en utilisant la solution en forme fermée comme indiqué dans l'équation suivante :\n","\n","$$\n","\\boldsymbol w = (\\boldsymbol X^T\\boldsymbol X)^{-1}\\boldsymbol X^T\\boldsymbol Y\n","$$\n","\n","X représente les entrées, et Y les cibles."],"metadata":{"id":"K6VpvJ_yxS59"}},{"cell_type":"code","source":["def NormalEquation(inputs, targets):\n","  # calculate the parameter w and return it\n","  w = np.linalg.inv(inputs.T.dot(inputs)).dot((inputs.T).dot(targets))\n","  return w"],"metadata":{"id":"IkaV15sENl89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#################################################################################################################"],"metadata":{"id":"N2c2uYaD3R3E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Évaluons le modèle en prenant un exemple des données de test, puis calculons l'EQM entre la prédiction du modèle et la cible."],"metadata":{"id":"7oKTKSDG3Se7"}},{"cell_type":"code","source":["w = NormalEquation(X_train, Y_train)      # All the parameter estimation should be done using  only the training data."],"metadata":{"id":"sE8GItUrQRa4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w"],"metadata":{"id":"U82ekQb6Hm2n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(X_test, w):\n","  y_pred = X_test.dot(w)\n","  return y_pred"],"metadata":{"id":"HEpVpoSNS0ll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_pred = predict(X_test, w)"],"metadata":{"id":"3a2bv8PdoTQb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_pred"],"metadata":{"id":"t_nyeZ4bx3KV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(MSE(Y_test, Y_pred))"],"metadata":{"id":"v5fmkYJ8TM4y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Methode descende de gradient"],"metadata":{"id":"zAtHBBXVDspZ"}},{"cell_type":"code","source":["def gradient(X, Y, o, learning_rate) :\n","  n = len(Y) # la taille de Y\n","  return learning_rate*((X.T).dot(X.dot(o)  - Y))*(1/n)"],"metadata":{"id":"8IM8fTrSHqca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fit(X_train,Y_train, lr) :\n","  w = np.zeros((X_train.shape[1], 1))  \n","  max_iters = 20 # max number of iterations\n","\n","  for  i in range(0,max_iters): \n","      w = w - gradient(X_train, Y_train, w, lr)\n","      print(\" iteration \", i ,\" : current_w = \\n\", w)\n","  print(\"  Local Minimum w :  \\n\", w)\n","  return w"],"metadata":{"id":"DU5BpmD-qF43"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["o = fit(X_train,Y_train, 0.9)"],"metadata":{"id":"4G1U6cy3xZht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_gradient = predict(X_test, o)"],"metadata":{"id":"5yl9T-kZLu1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_gradient"],"metadata":{"id":"3ZdneN2-Mscl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mse = MSE(Y_test, y_gradient)\n","print(MSE)"],"metadata":{"id":"XxrJ50pxLvL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ouJwWkKeLvfM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creer une classe et inserer les differentes methodes mse, predict, train implementer plus haut."],"metadata":{"id":"E3fFCG8IGrBZ"}},{"cell_type":"code","source":["class LR:\n","   \n","  def __init__(self, lr):\n","    self.lr = lr\n","\n","  def fit2(X_train, Y_train, n, lr): # descente gradient stochastique\n","      current_o = np.zeros((X_train.shape[1] , 1))\n","      max_iters = 15 # max number of iterations\n","\n","      for i in range(0,max_iters) :\n","          previous_o = current_o \n","          rd_nmber = random.choice(np.arange(0, X_train.shape[0]))\n","          X_line = X_train[rd_nmber, :].reshape([1 , X_train.shape[1] ]) \n","          Y_line = Y_train[rd_nmber, 0:1]\n","          current_o = previous_o - lr*((X_line.T).dot((X_line).dot(previous_o)  - Y_line))*(1/n)\n","      return current_o\n","    \n","  def fit1(X_train,Y_train, n, lr) : # descente gradient batch\n","      current_o = np.zeros((X_train.shape[1], 1)) \n","      max_iters = 15 # max number of iterations\n","      for  i in range(0, max_iters):\n","          previous_o = current_o \n","          current_o = previous_o - lr*((X_train.T).dot(X_train.dot(previous_o) - Y_train))*(1/n)\n","      return current_o\n","\n","  def fit(self, X_train, Y_train): # cette methode renvoie w_batch et w_stochastique\n","    n = len(Y_train) # taille du jeu de donnee \n","    self.w_batch = LR.fit1(X_train,Y_train, n , self.lr) # descente gradient batch\n","    self.w_stch = LR.fit2(X_train,Y_train,  n , self.lr) # descente gradient stochastique\n","    return True\n","\n","  def predict(self, X_test):\n","    return (X_test.dot(self.w_batch),  (X_test).dot(self.w_stch))\n","\n","  def mse(self, y_true, y_pred): \n","    n = len(y_true)\n","    mse = (np.sum(np.square(y_true - y_pred)))*(1/n)\n","    print(\"MSE : \", mse ) \n"],"metadata":{"id":"UA9hkwSsD1S_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = LR(lr= 0.000001)\n","print(model.lr)\n","model.fit(X_train= X_train, Y_train= Y_train)\n","y_pre_btch, y_pre_stch  = model.predict(X_test = X_test)\n","print(y_pre_btch) # valeur de Y selon la methode du gradient batch\n","print(y_pre_stch) #valeur de Y selon la methode du gradient stochastique\n","model.mse(y_true= Y_test, y_pred= y_pre_btch) # mse batch\n","model.mse(y_true= Y_test, y_pred= y_pre_stch) # mse stochastique"],"metadata":{"id":"-h3-uEyshTX-"},"execution_count":null,"outputs":[]}]}